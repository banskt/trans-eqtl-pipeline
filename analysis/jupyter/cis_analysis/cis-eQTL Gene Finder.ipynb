{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "sys.path.append('../')\n",
    "sys.path.append('/usr/users/fsimone/tejaas')\n",
    "from utils import readgtf\n",
    "import collections\n",
    "from utils import readgtf\n",
    "\n",
    "gene_info = readgtf.gencode_v12(\"/cbscratch/franco/datasets/GENCODE/gencode.v26.annotation.gtf.gz\", trim=True)\n",
    "gene_info_dict = collections.defaultdict(dict)\n",
    "for gene in gene_info:\n",
    "    gene_info_dict[gene.chrom][gene.ensembl_id] = gene.typ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mpmath\n",
    "from operator import attrgetter\n",
    "\n",
    "mpmath.mp.dps = 50\n",
    "def pvalue(x): return float(mpmath.log10(1 - 0.5 * (1 + mpmath.erf(x/mpmath.sqrt(2)))))\n",
    "\n",
    "SNPRES_FIELDS = ['rsid', 'chrom', 'pos', 'logp', 'fdr', 'target']\n",
    "class SNPRes(collections.namedtuple('_SNPRes', SNPRES_FIELDS)):\n",
    "    __slots__ = ()\n",
    "    \n",
    "def tejaas_saikat(filepath):\n",
    "    res = list()\n",
    "    with open(filepath, 'r') as mfile:\n",
    "        next(mfile)\n",
    "        for line in mfile:\n",
    "            arr   = line.strip().split(\"\\t\")\n",
    "            rsid  = arr[0]\n",
    "            chrom = int(arr[1])\n",
    "            pos   = int(arr[2])\n",
    "            p     = float(arr[3])\n",
    "            logp  = np.log10(p) if p!=0 else np.log10(10e-30)\n",
    "            res.append(SNPRes(rsid=rsid, chrom=chrom, pos=pos, logp=-logp, fdr=None, target=None))\n",
    "    return res\n",
    "        \n",
    "def tejaas(filepath):\n",
    "    res = list()\n",
    "    with open(filepath, 'r') as mfile:\n",
    "        next(mfile)\n",
    "        for line in mfile:\n",
    "            arr   = line.strip().split(\"\\t\")\n",
    "            rsid  = arr[0]\n",
    "            pos   = int(arr[1])\n",
    "            p     = float(arr[5])\n",
    "            chrom = int(arr[6])\n",
    "            q     = float(arr[2])\n",
    "            mu    = float(arr[3])\n",
    "            sigma = float(arr[4])\n",
    "            if sigma == 0:\n",
    "                continue\n",
    "            logp  = np.log10(p) if p != 0 else pvalue( (q - mu) / sigma)\n",
    "            res.append(SNPRes(rsid=rsid, chrom=chrom, pos=pos, logp=-logp, fdr=None, target=None))\n",
    "    return res\n",
    "\n",
    "def matrixeqtl(filepath, chrom, fdrcutoff):\n",
    "    res = list()\n",
    "    if not os.path.exists(filepath) or os.stat(filepath).st_size == 0:\n",
    "        print(\"File empty or does not exist\")\n",
    "        return res\n",
    "    with open(filepath, 'r') as mfile:\n",
    "        next(mfile)\n",
    "        for line in mfile:\n",
    "            arr  = line.strip().split(\"\\t\")\n",
    "            rsid = arr[0]\n",
    "            pos = int(rsid.split(\"_\")[1])\n",
    "            gene = arr[1].split(\".\")[0]\n",
    "            logp = np.log10(float(arr[4]))\n",
    "            fdr  = np.log10(float(arr[5]))\n",
    "            if fdr > fdrcutoff:\n",
    "                break\n",
    "            res.append(SNPRes(rsid=rsid, chrom=chrom, pos=pos, logp=-logp, fdr=-fdr, target=gene))\n",
    "    return res\n",
    "\n",
    "def matrixeqtl_signif(filepath, snp_maf_dict):\n",
    "    res = list()\n",
    "    discard = 0\n",
    "    with open(filepath, 'r') as mfile:\n",
    "        next(mfile)\n",
    "        for line in mfile:\n",
    "            arr  = line.strip().split(\"\\t\")\n",
    "            chrom = arr[0]\n",
    "            rsid = arr[1]\n",
    "            if not snp_maf_dict[rsid]:\n",
    "                discard += 1\n",
    "                continue\n",
    "            pos = arr[2]\n",
    "            gene = arr[5]\n",
    "            logp = float(arr[3])\n",
    "            fdr  = float(arr[4])\n",
    "            res.append(SNPRes(rsid=rsid, chrom=chrom, pos=pos, logp=logp, fdr=fdr, target=gene))\n",
    "    # print(\"Discarded {:d} SNPs with low MAF\".format(discard))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4522283\n"
     ]
    }
   ],
   "source": [
    "# Filter by allowed snps according to MAF\n",
    "basepath = \"/cbscratch/franco/trans-eqtl/dev-pipeline/gtex_v8_lncRNA/\"\n",
    "baseoutdir = os.path.join(basepath, \"cis_eqtls_analysis\")\n",
    "if not os.path.exists(baseoutdir): os.makedirs(baseoutdir)\n",
    "\n",
    "title = \"maf1\"\n",
    "maffile = \"/cbscratch/franco/datasets/gtex_v8/genotypes/vcfs_0.01/gtex_v8_snpinfo.txt\"\n",
    "randompath = \"/usr/users/fsimone/vcfs_0.01/\"\n",
    "\n",
    "# title = \"maf5\"\n",
    "# maffile = \"/cbscratch/franco/datasets/gtex_v8/genotypes/vcfs_0.05/gtex_v8_snpinfo.txt\"\n",
    "# randompath = \"/usr/users/fsimone/vcfs_0.05/\"\n",
    "\n",
    "outdir = os.path.join(baseoutdir, title)\n",
    "if not os.path.exists(outdir): os.makedirs(outdir)\n",
    "\n",
    "# NTOT_SNPS_MAF1 = 4522283\n",
    "# NTOT_SNPS_MAF5 = 2135526\n",
    "\n",
    "NTOT_SNPS = 0\n",
    "snp_maf_dict = collections.defaultdict(lambda:False)\n",
    "with open(maffile) as instream:\n",
    "    for line in instream:\n",
    "        snp_maf_dict[line.rstrip().split()[1]] = True\n",
    "        NTOT_SNPS += 1\n",
    "print(NTOT_SNPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from utils import utils\n",
    "tissue_file = \"/usr/users/fsimone/trans-eqtl-pipeline/main/tissues.txt\"\n",
    "tissues, descriptions = utils.read_tissues(tissue_file)\n",
    "\n",
    "dataset = \"gtex_v8\"\n",
    "expressions = [\"tmm_cclm\"]\n",
    "methods = [\"matrixeqtl\"]\n",
    "chroms = [str(x) for x in np.arange(1,23)]\n",
    "fdrcutoff = np.log10(0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: as  - Files exists\n",
      "Processing: av  - Files exists\n",
      "Processing: ag  - Files exists\n",
      "Processing: aa  - Files exists\n",
      "Processing: ac  - Files exists\n",
      "Processing: at  - Files exists\n",
      "Processing: bam  - Files exists\n",
      "Processing: ban  - Files exists\n",
      "Processing: bca  - Files exists\n",
      "Processing: bceh  - Files exists\n",
      "Processing: bce  - Files exists\n",
      "Processing: bco  - Files exists\n",
      "Processing: bfr  - Files exists\n",
      "Processing: bhi  - Files exists\n",
      "Processing: bhy  - Files exists\n",
      "Processing: bnu  - Files exists\n",
      "Processing: bpu  - Files exists\n",
      "Processing: bsp  - Files exists\n",
      "Processing: bsu  - Files exists\n",
      "Processing: br  - Files exists\n",
      "Processing: ebv  - Files exists\n",
      "Processing: fib  - Files exists\n",
      "Processing: cols  - Files exists\n",
      "Processing: colt  - Files exists\n",
      "Processing: esog  - Files exists\n",
      "Processing: esom  - Files exists\n",
      "Processing: esomu  - Files exists\n",
      "Processing: haa  - Files exists\n",
      "Processing: hlv  - Files exists\n",
      "Processing: kc  - Files exists\n",
      "Processing: liv  - Files exists\n",
      "Processing: lu  - Files exists\n",
      "Processing: msg  - Files exists\n",
      "Processing: ms  - Files exists\n",
      "Processing: nt  - Files exists\n",
      "Processing: pan  - Files exists\n",
      "Processing: pit  - Files exists\n",
      "Processing: snse  - Files exists\n",
      "Processing: sse  - Files exists\n",
      "Processing: si  - Files exists\n",
      "Processing: spl  - Files exists\n",
      "Processing: sto  - Files exists\n",
      "Processing: thy  - Files exists\n",
      "Processing: wb  - Files exists\n"
     ]
    }
   ],
   "source": [
    "def write_eqtls(snp_res, outfile):\n",
    "    with open(outfile, 'w') as outstream:\n",
    "        for g in snp_res:\n",
    "            line = \"{:s}\\t{:s}\\t{:d}\\t{:g}\\t{:g}\\t{:s}\\n\".format(g.chrom, g.rsid, g.pos, g.logp, g.fdr, g.target)\n",
    "            outstream.write(line)\n",
    "\n",
    "basepath_patch=\"/cbscratch/franco/trans-eqtl/dev-pipeline/gtex_v8_lncRNA/\"\n",
    "for tissue in tissues:\n",
    "    gtex_t = \"-\".join([dataset, tissue])\n",
    "    print(\"Processing: {:s}\".format(tissue), end=\" \")\n",
    "    for expression in expressions:\n",
    "        for method in methods:\n",
    "            tissue_path = os.path.join(basepath_patch, expression, gtex_t)\n",
    "            signif_cisfile = os.path.join(basepath_patch, expression, gtex_t, method, \"cis_eqtl_signif_fdr0.05.txt\")\n",
    "            signif_transfile = os.path.join(basepath_patch, expression, gtex_t, method, \"trans_eqtl_signif_fdr0.05.txt\")\n",
    "            if os.path.exists(tissue_path):\n",
    "                if not os.path.exists(signif_cisfile) and not os.path.exists(signif_transfile):\n",
    "                    print(\"\")\n",
    "                    snp_res = list()\n",
    "                    trans_snp_res = list()\n",
    "                    for chrom in chroms:\n",
    "                        cisfile = os.path.join(basepath_patch, expression, gtex_t, method, \"chr\"+chrom, \"cis_eqtl.txt.pos\")\n",
    "                        snp_res += matrixeqtl(cisfile, chrom, fdrcutoff)        \n",
    "                        transfile = os.path.join(basepath_patch, expression, gtex_t, method, \"chr\"+chrom, \"trans_eqtl.txt.pos\")\n",
    "                        trans_snp_res += matrixeqtl(transfile, chrom, fdrcutoff)\n",
    "                    write_eqtls(snp_res, signif_cisfile)\n",
    "                    write_eqtls(trans_snp_res, signif_transfile)\n",
    "                else:\n",
    "                    print(\" - Files exists\")\n",
    "            else:\n",
    "                print(tissue_path, \"does not exist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cis_typespecific_eqtls(cistrans_target_eqtls, genetype_dict):\n",
    "    cis_typespecific_eqtls = [x for x in cistrans_target_eqtls if genetype_dict[x.target]]\n",
    "    \n",
    "    uniq_cis_snps = list(set([x.rsid for x in cis_typespecific_eqtls]))\n",
    "    unique_targets = list(set([x.target for x in cis_typespecific_eqtls]))\n",
    "    return cis_typespecific_eqtls, uniq_cis_snps, unique_targets\n",
    "\n",
    "def cross_ref_cis_trans(trans_ids, cis_eqtls):\n",
    "    cis_ids = list(set([x.rsid for x in cis_eqtls]))\n",
    "    \n",
    "    #Intersection between cis-eqtls (MatrixEQTL) and trans-eqtls (TEJAAS)\n",
    "    cis_trans_eqtls_ids = list(set.intersection(set(trans_ids), set(cis_ids)))\n",
    "    \n",
    "    #set up a dict for fast look up later\n",
    "    cis_trans_dict = dict()\n",
    "    for x in cis_trans_eqtls_ids:\n",
    "        cis_trans_dict[x] = True\n",
    "    \n",
    "    # List of cis-trans-eqtls with its target gene\n",
    "    cis_target_eqtls = [x for x in cis_eqtls if cis_trans_dict.get(x.rsid, False)]\n",
    "\n",
    "    return cis_trans_eqtls_ids, cis_target_eqtls\n",
    "\n",
    "def crossref_trans_tejaas(transeqtls, cis_eqtls):\n",
    "    trans_ids = [x.rsid for x in transeqtls]\n",
    "    a, b = cross_ref_cis_trans(trans_ids, cis_eqtls)\n",
    "    return a, b\n",
    "\n",
    "import random\n",
    "\n",
    "def get_cistype_fractions(ciseqtls, valid_types, alltypes_dict):\n",
    "    cistype_frac_dict = dict()\n",
    "    NCIS = len(list(set([x.rsid for x in ciseqtls])))\n",
    "    for gtype in valid_types:\n",
    "        cishits = list()\n",
    "        for ciseqtl in ciseqtls:\n",
    "            if alltypes_dict[gtype][ciseqtl.target]:\n",
    "                cishits.append(ciseqtl.rsid)\n",
    "        NCIS_TYPE = len(list(set(cishits)))\n",
    "        cistype_frac_dict[gtype] = NCIS_TYPE / NCIS\n",
    "        # print(\"CIS_frac:\", gtype, NCIS_TYPE, NCIS)\n",
    "    return cistype_frac_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as\n",
      "Found 33 cis Snps targeting FOXP2\n",
      "4 close SNPs!\n",
      "av\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "ag\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "aa\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "ac\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "at\n",
      "Found 7 cis Snps targeting FOXP2\n",
      "bam\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "ban\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "bca\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "bceh\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "bce\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "bco\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "bfr\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "bhi\n",
      "Found 2 cis Snps targeting FOXP2\n",
      "bhy\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "bnu\n",
      "Found 3 cis Snps targeting FOXP2\n",
      "bpu\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "bsp\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "bsu\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "br\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "ebv\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "fib\n",
      "Found 22 cis Snps targeting FOXP2\n",
      "cols\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "colt\n",
      "Found 11 cis Snps targeting FOXP2\n",
      "2 close SNPs!\n",
      "esog\n",
      "Found 4 cis Snps targeting FOXP2\n",
      "esom\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "esomu\n",
      "Found 3 cis Snps targeting FOXP2\n",
      "haa\n",
      "Found 5 cis Snps targeting FOXP2\n",
      "hlv\n",
      "Found 2 cis Snps targeting FOXP2\n",
      "kc\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "liv\n",
      "Found 5 cis Snps targeting FOXP2\n",
      "lu\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "msg\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "ms\n",
      "Found 4 cis Snps targeting FOXP2\n",
      "nt\n",
      "Found 1 cis Snps targeting FOXP2\n",
      "pan\n",
      "Found 4 cis Snps targeting FOXP2\n",
      "pit\n",
      "Found 4 cis Snps targeting FOXP2\n",
      "snse\n",
      "Found 5 cis Snps targeting FOXP2\n",
      "1 close SNPs!\n",
      "sse\n",
      "Found 13 cis Snps targeting FOXP2\n",
      "1 close SNPs!\n",
      "si\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "spl\n",
      "Found 0 cis Snps targeting FOXP2\n",
      "sto\n",
      "Found 14 cis Snps targeting FOXP2\n",
      "thy\n",
      "Found 17 cis Snps targeting FOXP2\n",
      "4 close SNPs!\n",
      "wb\n",
      "Found 0 cis Snps targeting FOXP2\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "########### MAF 0.01 ##############\n",
    "###################################\n",
    "\n",
    "TARGET = \"ENSG00000128573\"   \n",
    "    \n",
    "meqtl_expr  = \"tmm_cclm\"\n",
    "tejaas_expr = \"raw\"\n",
    "\n",
    "# basepath = \"/cbscratch/franco/trans-eqtl/dev-pipeline/gtex_v8_new\"\n",
    "\n",
    "res_dict = dict()\n",
    "pair_res_dict = dict()\n",
    "for tissue in tissues:\n",
    "    gtex_t = \"-\".join([dataset, tissue])\n",
    "    print(tissue)\n",
    "    \n",
    "    tejaas_file = os.path.join(basepath, \"raw\", \"gtex_v8-\"+tissue, \"tejaas\", \"permnull_sb0.1_knn30\", \"trans_eqtls_0.0001.txt\") #5e-08.txt\")\n",
    "    if not os.path.exists(tejaas_file):\n",
    "        print(\"{:s} has no trans-eqtl results\".format(tissue))\n",
    "        continue\n",
    "    transeqtls = tejaas(tejaas_file)\n",
    "    transeqtls = [x for x in transeqtls if snp_maf_dict[x.rsid]]\n",
    "    \n",
    "    if len(transeqtls) == 0:\n",
    "        print(\"{:s} has less no trans-eqtls\".format(tissue))\n",
    "        continue\n",
    "    \n",
    "    signif_cisfile = os.path.join(basepath, meqtl_expr, gtex_t, \"matrixeqtl\", \"cis_eqtl_signif_fdr0.05.txt\")\n",
    "    if not os.path.exists(signif_cisfile) or os.stat(signif_cisfile).st_size == 0:\n",
    "        print(\"{:s} has no cis-file (probably no covariates)\".format(tissue))\n",
    "        continue\n",
    "    ciseqtls = matrixeqtl_signif(signif_cisfile, snp_maf_dict)\n",
    "    cis_ids = list(set([x.rsid for x in ciseqtls]))\n",
    "    \n",
    "    if len(ciseqtls) == 0:\n",
    "        print(\"{:s} has less no cis-eqtls\".format(tissue))\n",
    "        continue\n",
    "    \n",
    "    cis_trans_eqtls_ids, cistrans_target_eqtls = crossref_trans_tejaas(transeqtls, ciseqtls)\n",
    "    \n",
    "    cis_targets = [x for x in ciseqtls if x.target.startswith(TARGET)]\n",
    "    print(\"Found {:d} cis Snps targeting FOXP2\".format(len(cis_targets)))\n",
    "    \n",
    "    found_targets = [x for x in cistrans_target_eqtls if x.target.startswith(TARGET)]\n",
    "    if len(found_targets) > 0:\n",
    "        print(\"Found!\")\n",
    "        print(found_targets)  \n",
    "    \n",
    "    \n",
    "    dist = 10000\n",
    "    pairs = list()\n",
    "    for t in transeqtls:\n",
    "        if t.chrom == 7:\n",
    "            for c in cis_targets:\n",
    "                diff = np.abs(int(t.pos) - int(c.pos))\n",
    "                if diff < dist:\n",
    "                    pair = (t, c)\n",
    "                    pairs.append(pair)\n",
    "    if len(pairs) > 0:\n",
    "        print(\"{:d} close SNPs!\".format(len(pairs)))\n",
    "        pair_res_dict[tissue] = pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(SNPRes(rsid='chr7_114689251_C_A_b38', chrom=7, pos=114689251, logp=5.56091847996197, fdr=None, target=None),\n",
       "  SNPRes(rsid='chr7_114698760_T_C_b38', chrom='7', pos='114698760', logp=3.47237, fdr=2.03479, target='ENSG00000128573')),\n",
       " (SNPRes(rsid='chr7_114694515_A_G_b38', chrom=7, pos=114694515, logp=4.058319155997669, fdr=None, target=None),\n",
       "  SNPRes(rsid='chr7_114698760_T_C_b38', chrom='7', pos='114698760', logp=3.47237, fdr=2.03479, target='ENSG00000128573')),\n",
       " (SNPRes(rsid='chr7_114695200_C_T_b38', chrom=7, pos=114695200, logp=5.56091847996197, fdr=None, target=None),\n",
       "  SNPRes(rsid='chr7_114698760_T_C_b38', chrom='7', pos='114698760', logp=3.47237, fdr=2.03479, target='ENSG00000128573')),\n",
       " (SNPRes(rsid='chr7_114697041_A_G_b38', chrom=7, pos=114697041, logp=5.56091847996197, fdr=None, target=None),\n",
       "  SNPRes(rsid='chr7_114698760_T_C_b38', chrom='7', pos='114698760', logp=3.47237, fdr=2.03479, target='ENSG00000128573'))]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.754228703338169e-06"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(10,-5.56)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
